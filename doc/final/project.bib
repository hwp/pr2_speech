
@article{vincent_blind_2014,
	title = {From Blind to Guided Audio Source Separation},
	url = {http://hal.inria.fr/hal-00922378},
	abstract = {Audio is a domain where signal separation has long been considered as a fascinating objective, potentially offering a wide range of new possibilities and experiences in professional and personal contexts, by better taking advantage of audio material and finely analyzing complex acoustic scenes. It has thus always been a major area for research in signal separation and an exciting challenge for industrial applications. Starting with blind separation of toy mixtures in the mid 90's, research has progressed up to real-world scenarios today, with applications to speech enhancement and recognition, music editing, {3D} sound rendering, and audio information retrieval, among others. This has mostly been made possible by the development of increasingly informed separation techniques incorporating knowledge about the sources and/or the mixtures at hand. For instance, speech source separation for remote conferencing can benefit from prior knowledge of the room geometry and/or the names of the speakers, while music remastering will exploit instrument characteristics and knowledge of sound engineers mixing habits. After a brief historical account, we provide an overview of recent and ongoing research in this field, illustrating a variety of models and techniques designed so as to guide the audio source separation process towards efficient and robust solutions.},
	urldate = {2014-03-11},
	journal = {{IEEE} Signal Processing Magazine},
	author = {Vincent, Emmanuel and Bertin, Nancy and Gribonval, Rémi and Bimbot, Frédéric},
	month = may,
	year = {2014},
	file = {Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/B2XZSN8M/Vincent et al. - 2014 - From blind to guided audio source separation.pdf:application/pdf;Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/GWZVPJIK/en.html:text/html}
}

@inproceedings{lee_combining_1998,
	title = {Combining time-delayed decorrelation and {ICA:} towards solving the cocktail party problem},
	volume = {2},
	shorttitle = {Combining time-delayed decorrelation and {ICA}},
	doi = {10.1109/ICASSP.1998.675498},
	abstract = {We present methods to separate blindly mixed signals recorded in a room. The learning algorithm is based on the information maximization in a single layer neural network. We focus on the implementation of the learning algorithm and on issues that arise when separating speakers in room recordings. We used an infomax approach in a feedforward neural network implemented in the frequency domain using the polynomial filter matrix algebra technique. A fast convergence speed was achieved by using a time-delayed decorrelation method as a preprocessing step. Under minimum-phase mixing conditions this preprocessing step was sufficient for the separation of signals. These methods successfully separated a recorded voice with music in the background (cocktail party problem). Finally, we discuss problems that arise in real world recordings and their potential solutions},
	booktitle = {Proceedings of the 1998 {IEEE} International Conference on Acoustics, Speech and Signal Processing, 1998},
	author = {Lee, Te-Won and Ziehe, A. and Orglmeister, R. and Sejnowski, T.},
	month = may,
	year = {1998},
	keywords = {architectural acoustics, audio recording, audio system, blindly mixed signals, cocktail party problem solution, Convergence, convergence of numerical methods, correlation methods, Decorrelation, delays, Disk recording, fast convergence speed, feedforward neural nets, feedforward neural network architecture, Feedforward neural networks, filtering theory, Filters, frequency domain, Frequency domain analysis, frequency-domain synthesis, {ICA}, independent component analysis, information maximization, learning algorithm, learning (artificial intelligence), Matrices, matrix algebra, minimum-phase mixing conditions, music, neural net architecture, Neural networks, polynomial filter matrix algebra, Polynomials, preprocessing step, real world recordings, recorded voice, room recordings, signal separation, single layer neural network, speech processing, time-delayed decorrelation},
	pages = {1249--1252 vol.2},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/CXUWPJDN/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/QKC9JVEE/Lee et al. - 1998 - Combining time-delayed decorrelation and ICA towa.pdf:application/pdf}
}

@inproceedings{vincent_blind_2005,
	title = {Blind audio source separation - A critical review},
	url = {http://hal.inria.fr/inria-00545504},
	urldate = {2014-03-11},
	author = {Vincent, Emmanuel},
	year = {2005},
	file = {Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/VXKMTZZT/en.html:text/html}
}

@article{ozerov_general_2012,
	title = {A General Flexible Framework for the Handling of Prior Information in Audio Source Separation},
	volume = {20},
	url = {http://hal.archives-ouvertes.fr/hal-00626962},
	abstract = {Most of audio source separation methods are developed for a particular scenario characterized by the number of sources and channels and the characteristics of the sources and the mixing process. In this paper we introduce a general audio source separation framework based on a library of structured source models that enable the incorporation of prior knowledge about each source via user-specifiable constraints. While this framework generalizes several existing audio source separation methods, it also allows to imagine and implement new efficient methods that were not yet reported in the literature. We first introduce the framework by describing the model structure and constraints, explaining its generality, and summarizing its algorithmic implementation using a generalized expectation-maximization algorithm. Finally, we illustrate the above-mentioned capabilities of the framework by applying it in several new and existing configurations to different source separation problems. We have released a software tool named Flexible Audio Source Separation Toolbox ({FASST)} implementing a baseline version of the framework in Matlab.},
	number = {4},
	urldate = {2014-03-12},
	journal = {{IEEE} Transactions on Audio, Speech and Language Processing},
	author = {Ozerov, Alexey and Vincent, Emmanuel and Bimbot, Frédéric},
	month = may,
	year = {2012},
	keywords = {Audio source separation, expectation-maximization, local Gaussian model, nonnegative matrix factorization},
	pages = {1118--1133},
	file = {Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/PA2RMA27/Ozerov et al. - 2012 - A General Flexible Framework for the Handling of P.pdf:application/pdf;Snapshot:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/E92HFVXA/hal-00626962.html:text/html}
}

@article{souden_multichannel_2013,
	title = {A Multichannel {MMSE-Based} Framework for Speech Source Separation and Noise Reduction},
	volume = {21},
	issn = {1558-7916},
	doi = {10.1109/TASL.2013.2263137},
	abstract = {We propose a new framework for joint multichannel speech source separation and acoustic noise reduction. In this framework, we start by formulating the minimum-mean-square error ({MMSE)-based} solution in the context of multiple simultaneous speakers and background noise, and outline the importance of the estimation of the activities of the speakers. The latter is accurately achieved by introducing a latent variable that takes N+1 possible discrete states for a mixture of N speech signals plus additive noise. Each state characterizes the dominance of one of the N+1 signals. We determine the posterior probability of this latent variable, and show how it plays a twofold role in the {MMSE-based} speech enhancement. First, it allows the extraction of the second order statistics of the noise and each of the speech signals from the noisy data. These statistics are needed to formulate the multichannel Wiener-based filters (including the minimum variance distortionless response). Second, it weighs the outputs of these linear filters to shape the spectral contents of the signals' estimates following the associated target speakers' activities. We use the spatial and spectral cues contained in the multichannel recordings of the sound mixtures to compute the posterior probability of this latent variable. The spatial cue is acquired by using the normalized observation vector whose distribution is well approximated by a Gaussian-mixture-like model, while the spectral cue can be captured by using a pre-trained Gaussian mixture model for the log-spectra of speech. The parameters of the investigated models and the speakers' activities (posterior probabilities of the different states of the latent variable) are estimated via expectation maximization. Experimental results including comparisons with the well-known independent component analysis and masking are provided to demonstrate the efficiency of the proposed framework.},
	number = {9},
	journal = {{IEEE} Transactions on Audio, Speech, and Language Processing},
	author = {Souden, M. and Araki, S. and Kinoshita, K. and Nakatani, T. and Sawada, H.},
	month = sep,
	year = {2013},
	keywords = {acoustic noise reduction, background noise, blind source separation, expectation-maximisation algorithm, expectation maximization estimation, Gaussian distribution, Gaussian-mixture-like model, higher order statistics, independent component analysis, joint multichannel speech source separation, latent variable, least mean squares methods, linear filters, log-spectra, microphone arrays, minimum-mean-square error, minimum-mean-square error based solution, minimum variance distortionless response, {MMSE-based} speech enhancement, multichannel {MMSE-based} framework, multichannel recordings, multichannel Wiener-based filters, multiple simultaneous speakers, N+1 possible discrete states, Noise reduction, normalized observation vector, N speech signals plus additive noise mixture, posterior probability, pretrained Gaussian mixture model, probability, second order statistics, signal denoising, signal estimates, sound mixtures, Speech enhancement, speech signals, Wiener filter, Wiener filters},
	pages = {1913--1928},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/9ZSSTWQV/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/M58VVUX3/Souden et al. - 2013 - A Multichannel MMSE-Based Framework for Speech Sou.pdf:application/pdf}
}

@incollection{gribonval_sparse_2010,
	title = {Sparse Component Analysis},
	volume = {1},
	booktitle = {Handbook of Blind Source Separation, Independent Component Analysis and Applications},
	publisher = {Academic Press},
	author = {Gribonval, R. and Zibulevsky, M.},
	year = {2010},
	pages = {367--420},
	file = {Gribonval_Zibulevsky_SCA_chapter.pdf:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/KE4F82SW/Gribonval_Zibulevsky_SCA_chapter.pdf:application/pdf}
}

@article{nawab_signal_1983,
	title = {Signal reconstruction from short-time Fourier transform magnitude},
	volume = {31},
	issn = {0096-3518},
	doi = {10.1109/TASSP.1983.1164162},
	abstract = {In this paper, a signal is shown to be uniquely represented by the magnitude of its short-time Fourier transform ({STFT)} under mild restrictions on the signal and the analysis window of the {STFT.} Furthermore, various algorithms are developed which reconstruct signal from appropriate samples of the {STFT} magnitude. Several of the algorithms can also be used to obtain signal estimates from the processed {STFT} magnitude, which generally does not have a valid short-time structure. These algorithms are successfully applied to the time-scale modification and noise reduction problems in speech processing. Finally, the results presented here have similar potential for other application areas, including those with multidimensional signals.},
	number = {4},
	journal = {{IEEE} Transactions on Acoustics, Speech and Signal Processing},
	author = {Nawab, {S.H.} and Quatieri, {T.F.} and Lim, {J.S.}},
	month = aug,
	year = {1983},
	keywords = {Fourier transforms, Image reconstruction, Noise reduction, Phase noise, Signal analysis, Signal processing algorithms, Signal reconstruction, Speech enhancement, speech processing, Speech synthesis},
	pages = {986--998},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/I6PSEVHG/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/39XVHV2H/Nawab et al. - 1983 - Signal reconstruction from short-time Fourier tran.pdf:application/pdf}
}

@article{portnoff_time-frequency_1980,
	title = {Time-frequency representation of digital signals and systems based on short-time Fourier analysis},
	volume = {28},
	issn = {0096-3518},
	doi = {10.1109/TASSP.1980.1163359},
	abstract = {This paper develops a representation for discrete-time signals and systems based on short-time Fourier analysis. The short-time Fourier transform and the time-varying frequency response are reviewed as representations for signals and linear time-varying systems. The problems of representing a signal by its short-time Fourier transform and synthesizing a signal from its transform are considered. A new synthesis equation is introduced that is sufficiently general to describe apparently different synthesis methods reported in the literature. It is shown that a class of linear-filtering problems can be represented as the product of the time-varying frequency response of the filter multiplied by the short-time Fourier transform of the input signal. The representation of a signal by samples of its short-time Fourier transform is applied to the linear filtering problem. This representation is of practical significance because there exists a computationally efficient algorithm for implementing such systems. Finally, the methods of fast convolution age considered as special cases of this representation.},
	number = {1},
	journal = {{IEEE} Transactions on Acoustics, Speech and Signal Processing},
	author = {Portnoff, Michael R.},
	month = feb,
	year = {1980},
	keywords = {Differential equations, Discrete Fourier transforms, Fourier transforms, Frequency response, Maximum likelihood detection, Nonlinear filters, Signal analysis, Signal synthesis, Time frequency analysis, Time varying systems},
	pages = {55--69},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/AC5MUC4G/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/CIBNQB5X/Portnoff - 1980 - Time-frequency representation of digital signals a.pdf:application/pdf}
}

@article{allen_short_1977,
	title = {Short term spectral analysis, synthesis, and modification by discrete Fourier transform},
	volume = {25},
	issn = {0096-3518},
	doi = {10.1109/TASSP.1977.1162950},
	abstract = {A theory of short term spectral analysis, synthesis, and modification is presented with an attempt at pointing out certain practical and theoretical questions. The methods discussed here are useful in designing filter banks when the filter bank outputs are to be used for synthesis after multiplicative modifications are made to the spectrum.},
	number = {3},
	journal = {{IEEE} Transactions on Acoustics, Speech and Signal Processing},
	author = {Allen, {J.B.}},
	month = jun,
	year = {1977},
	keywords = {Band pass filters, Bandwidth, Channel bank filters, Discrete Fourier transforms, Filter bank, Frequency, Low pass filters, Signal analysis, Signal synthesis, spectral analysis},
	pages = {235--238},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/CES83M7U/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/UKMZBX6J/Allen - 1977 - Short term spectral analysis, synthesis, and modif.pdf:application/pdf}
}

@article{crochiere_weighted_1980,
	title = {A weighted overlap-add method of short-time Fourier {analysis/Synthesis}},
	volume = {28},
	issn = {0096-3518},
	doi = {10.1109/TASSP.1980.1163353},
	abstract = {In this correspondence we present a new structure and a simplified interpretation of short-time Fourier synthesis using synthesis windows. We show that this approach can be interpreted as a modification of the overlap-add method where we inverse the Fourier transform and window by the synthesis window prior to overlap-adding. This simplified interpretation results in a more efficient structure for short-time synthesis when a synthesis window is desired. In addition, we show how this structure can be used for analysis/synthesis applications which require different analysis and synthesis rates, such as time compression or expansion.},
	number = {1},
	journal = {{IEEE} Transactions on Acoustics, Speech and Signal Processing},
	author = {Crochiere, {R.E.}},
	month = feb,
	year = {1980},
	keywords = {Band pass filters, Channel bank filters, Discrete Fourier transforms, Filter bank, Fourier transforms, Sampling methods, Signal analysis, Signal synthesis, Speech analysis, Speech synthesis},
	pages = {99--102},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/XP6F5Q4M/articleDetails.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/PW7JXMNB/Crochiere - 1980 - A weighted overlap-add method of short-time Fourie.pdf:application/pdf}
}

@article{griffin_signal_1984,
	title = {Signal estimation from modified short-time Fourier transform},
	volume = {32},
	issn = {0096-3518},
	doi = {10.1109/TASSP.1984.1164317},
	abstract = {In this paper, we present an algorithm to estimate a signal from its modified short-time Fourier transform ({STFT).} This algorithm is computationally simple and is obtained by minimizing the mean squared error between the {STFT} of the estimated signal and the modified {STFT.} Using this algorithm, we also develop an iterative algorithm to estimate a signal from its modified {STFT} magnitude. The iterative algorithm is shown to decrease, in each iteration, the mean squared error between the {STFT} magnitude of the estimated signal and the modified {STFT} magnitude. The major computation involved in the iterative algorithm is the discrete Fourier transform ({DFT)} computation, and the algorithm appears to be real-time implementable with current hardware technology. The algorithm developed in this paper has been applied to the time-scale modification of speech. The resulting system generates very high-quality speech, and appears to be better in performance than any existing method.},
	number = {2},
	journal = {{IEEE} Transactions on Acoustics, Speech and Signal Processing},
	author = {Griffin, D. and Lim, {J.S.}},
	month = apr,
	year = {1984},
	keywords = {Degradation, Discrete Fourier transforms, Estimation theory, Fourier transforms, Hardware, Iterative algorithms, Monitoring, Sampling methods, Signal processing, Speech enhancement},
	pages = {236--243},
	file = {IEEE Xplore Abstract Record:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/TJSDJQ63/abs_all.html:text/html;IEEE Xplore Full Text PDF:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/B6KINXNJ/Griffin and Lim - 1984 - Signal estimation from modified short-time Fourier.pdf:application/pdf}
}

@article{politis_bias-corrected_1995,
	title = {{BIAS-CORRECTED} {NONPARAMETRIC} {SPECTRAL} {ESTIMATION}},
	volume = {16},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.1467-9892.1995.tb00223.x/abstract},
	number = {1},
	urldate = {2014-03-26},
	journal = {Journal of time series analysis},
	author = {Politis, Dimitris N. and Romano, Joseph P.},
	year = {1995},
	pages = {67–103},
	file = {tsa3ez.pdf:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/FKATHSH7/tsa3ez.pdf:application/pdf}
}

@techreport{heinzel_spectrum_2002,
	title = {Spectrum and spectral density estimation by the Discrete Fourier transform ({DFT)}, including a comprehensive list of window functions and some new flat-top windows},
	url = {http://helio.estec.esa.int/SP/LISAPATHFINDER/docs/Data_Analysis/GH_FFT.pdf},
	urldate = {2014-03-26},
	institution = {Max Planck Institute},
	author = {Heinzel, Gerhard and Rüdiger, A. and Schilling, Roland and Hannover, Teilinstitut},
	year = {2002},
	pages = {122},
	file = {GH_FFT.pdf:/home/hwp/.mozilla/firefox/1pw129hc.default-1394317684004/zotero/storage/B6IB6R5W/GH_FFT.pdf:application/pdf}
}